{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab7ac146",
   "metadata": {},
   "source": [
    "Goal - The point of this program is to scrape the daily discussion to see how many times a coin is mentioned.\n",
    "       You will then graph this information to compare it to the coin's performance in attempt to gauge any \n",
    "       correlation.\n",
    "       \n",
    "Method - Utilizing https://www.reddit.com/r/CryptoCurrency/search/?q=daily%20discussion&restrict_sr=1&sr_nsfw=\n",
    "         you should be able to obtain the url for each discussion. Then you can try BeautifulSoup or Selenium\n",
    "         to get the comments. You can also use PRAW if those don't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989320a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "import praw\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from praw.models import MoreComments \n",
    "from selenium import webdriver\n",
    "import time\n",
    "from datetime import date\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da90c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape CoinMarketCap for daily price and top 10 coins\n",
    "'''\n",
    "We will utilize https://coinmarketcap.com/ to see grab the name, alias, and current price of the top 10\n",
    "coins excluding: USD Coin, Tether, BNB, Binance USD. I'd like to have the Coin instances pull from this.\n",
    "\n",
    "Lessgettiiittt\n",
    "\n",
    "- Requests doesn't work because the page needs to scroll down to load more than the first 10 and your program\n",
    "wants more than this.\n",
    "'''\n",
    "#Via webdriver grab the data\n",
    "coin_url = 'https://coinmarketcap.com/'\n",
    "driver = webdriver.Chrome(chrome_driver_path)\n",
    "driver.get(coin_url)\n",
    "#This scrolls down to allow ~20 coins to be loaded into coin_soup\n",
    "driver.execute_script(\"window.scrollTo(0, 1500)\")\n",
    "coin_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "driver.close()\n",
    "coin_tag = coin_soup.find('div', class_ = 'h7vnx2-1 bFzXgL').find('tbody').find_all('tr') #All coins are in a <tr> tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ccbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create top 10 within top_10_list as (Name), (Alias), (Price)\n",
    "\n",
    "top_10_list = [(),(),(),(),(),(),(),(),(),()]\n",
    "skip_list = ['usd coin', 'tether', 'bnb', 'binance usd', 'Crypto.com Coin']\n",
    "coin_count = 0\n",
    "for coin in coin_tag:\n",
    "    if (coin.find_all('p')[1].text.lower()) not in skip_list:\n",
    "        if coin_count <= 9:\n",
    "            top_10_list[coin_count] = (coin.find_all('p')[1].text,coin.find_all('p')[2].text,coin.find_all('p')[3].text.split('$')[2]) \n",
    "            coin_count+=1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top Coins by Marketcap\n",
    "\n",
    "class Coin:\n",
    "    \n",
    "    def __init__(self, name, alias):\n",
    "        self.name = name\n",
    "        self.alias = alias\n",
    "\n",
    "#Define Coins\n",
    "coin0 = Coin(top_10_list[0][0], top_10_list[0][1])\n",
    "coin1 = Coin(top_10_list[1][0], top_10_list[1][1])\n",
    "coin2 = Coin(top_10_list[2][0], top_10_list[2][1])\n",
    "coin3 = Coin(top_10_list[3][0], top_10_list[3][1])\n",
    "coin4 = Coin(top_10_list[4][0], top_10_list[4][1])\n",
    "coin5 = Coin(top_10_list[5][0], top_10_list[5][1])\n",
    "coin6 = Coin(top_10_list[6][0], top_10_list[6][1])\n",
    "coin7 = Coin(top_10_list[7][0], top_10_list[7][1])\n",
    "coin8 = Coin(top_10_list[8][0], top_10_list[8][1])\n",
    "coin9 = Coin(top_10_list[9][0], top_10_list[9][1])\n",
    "coin_list = [coin0, coin1, coin2, coin3, coin4, coin5, coin6, coin7, coin8, coin9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc7f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Date\n",
    "today = date.today()\n",
    "tab_date = today.strftime(\"%B %Y\")\n",
    "full_date = today.strftime(\"%B %d %Y\")\n",
    "dd_search_date = today.strftime(\"%B_%d\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d65c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create copy for testing\n",
    "'''db_df_copy = copy.deepcopy(db_df) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b226b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load database (Sheetnames are saved as: Month Year. tab_date is used to load the correct sheet.)\n",
    "df_path = df_path\n",
    "try:\n",
    "    db_df = pd.read_excel(df_path, sheet_name = tab_date)\n",
    "except:\n",
    "    pass\n",
    "    #You need to be in a catch for when a new month needs to be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Dataframe db_df for comment scrape\n",
    "\n",
    "#Create Column for Any Coin not Previously in Top 10\n",
    "for coin in coin_list:\n",
    "    if coin.name.title() not in db_df.columns:\n",
    "        db_df[coin.name.title()] = 0\n",
    "\n",
    "#Drop Average and Total Columns\n",
    "for col in db_df.columns:\n",
    "    if 'Avg' in col or 'Total' in col:\n",
    "        db_df.drop(columns = [col], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c98b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare day_dict for comment scrape/count\n",
    "\n",
    "day_dict = {full_date: {}}\n",
    "\n",
    "day_dict[full_date] = {\n",
    "    coin0.name.title() : 0,\n",
    "    coin1.name.title() : 0,\n",
    "    coin2.name.title() : 0,\n",
    "    coin3.name.title() : 0,\n",
    "    coin4.name.title() : 0,\n",
    "    coin5.name.title() : 0,\n",
    "    coin6.name.title() : 0,\n",
    "    coin7.name.title() : 0,\n",
    "    coin8.name.title() : 0,\n",
    "    coin9.name.title() : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee08aa2",
   "metadata": {},
   "source": [
    "#### Parse Daily Discussion Links\n",
    "Grab daily discussion link based on the idea that Month_Date is included in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf15188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse Daily Discussion Links\n",
    "'''\n",
    "Grab daily discussion link based on the idea that Month_Date is included in the title.\n",
    "'''\n",
    "parent_url = 'https://www.reddit.com/r/CryptoCurrency/search/?q=daily%20discussion&restrict_sr=1&sr_nsfw='\n",
    "r = requests.get(parent_url)\n",
    "\n",
    "#Parse Daily Discussion link\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "container = soup.find('div', class_='QBfRw7Rj8UkxybFpX-USO')\n",
    "heads = container.find_all('a', href=True)\n",
    "\n",
    "#Grab Daily Discussion\n",
    "dd_link = ''\n",
    "for head in heads:\n",
    "    grab_href = head.get('href')\n",
    "    if 'http' in grab_href and dd_search_date in grab_href:\n",
    "        dd_link = grab_href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053abffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect PRAW Agent\n",
    "reddit_read_only = praw.Reddit(client_id = enter_your_id,\n",
    "                    client_secret= enter_your_secret,\n",
    "                    user_agent= enter_your_agent) #Hide sensitive information if you place this on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20852163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Comments from Daily Discussion Links\n",
    "'''\n",
    "Reddit utilizes JS to load more comments as you scroll down. Let's utilize PRAW to scrape comments\n",
    "'''\n",
    "def grab_comments():\n",
    "    submission = reddit_read_only.submission(url = dd_link)\n",
    "    for coin in coin_list:\n",
    "        count = 0\n",
    "        for comment in submission.comments:\n",
    "            if type(comment) == MoreComments:\n",
    "                submission.comments.replace_more(limit = 0)\n",
    "                for comment in submission.comments.list():\n",
    "                    if coin.name.lower() in comment.body.lower() or coin.alias.lower() in comment.body.lower():\n",
    "                        count+=1\n",
    "            elif coin.name.lower() in comment.body.lower() or coin.alias.lower() in comment.body.lower():\n",
    "                count+=1\n",
    "        day_dict[full_date][(coin.name).title()] = count                \n",
    "\n",
    "grab_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38462319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append to Dataframe db_df\n",
    "day_dict_df = pd.DataFrame(day_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eedc45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set index for db_df (.T transposes day_dict_df to match the formatting)\n",
    "db_df = db_df.rename(\n",
    "    columns = {'Unnamed: 0' :'Date'}).set_index('Date').append(day_dict_df.T).replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c58964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append to previous DataFrame\n",
    "df_path = historical_dataframe_path\n",
    "wb = openpyxl.load_workbook(df_path)\n",
    "ws=wb[tab_date]\n",
    "col_num = 0\n",
    "\n",
    "ws_dict = {} #Temporary storage of ws column header and column number\n",
    "\n",
    "#Create date\n",
    "ws.cell(row = ws.max_row + 1, column = 1).value = full_date\n",
    "ws.cell(row = ws.max_row + 1, column = 1).font = Font(bold=True)\n",
    "\n",
    "max_rows = ws.max_row + 1\n",
    "\n",
    "for i, cols in enumerate(ws.iter_cols(min_row = 1, max_row = 1, min_col = 2)):\n",
    "    for col in cols:\n",
    "        col_num = i + 2\n",
    "        ws_dict[col.value] = col_num\n",
    "for name in db_df.columns:\n",
    "    if name in ws_dict: #Fill in new comment count for previously captured coin\n",
    "        ws.cell(row = ws.max_row - 1, column = ws_dict[name]).value = db_df[name][full_date]\n",
    "    elif name not in ws_dict: #Create new column\n",
    "        print(name)\n",
    "        ws.cell(row = 1, column = ws.max_column + 1).value = name\n",
    "        ws.cell(row = ws.max_row + 1, column = ws.max_column + 1).value = db_df[name][full_date]\n",
    "        #Fill empty cells in new column\n",
    "        for rows in ws.iter_rows(min_row = 2, min_col = max_column, max_col = max_column):\n",
    "            for row in rows:\n",
    "                if row.value == None:\n",
    "                    row.value = 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append DataFrame.xlsx\n",
    "wb.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
